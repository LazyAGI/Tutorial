{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69efee8e",
   "metadata": {},
   "source": [
    "# 16 Advanced 4-Practical combat: Create a RAG system for paper Q&A with macro Q&A and chart generation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be6184",
   "metadata": {},
   "source": [
    "> In the previous course, we used the RAG knowledge we learned to build a paper-based question and answer system. However, when there are a large number of papers, for some statistical information, such as the number of papers in a certain direction, the number of papers in a certain conference, etc., it is impossible to retrieve this information only through traditional RAG. In this regard, this chapter will briefly review the previous content, and then upgrade it to complete an intelligent question and answer system that integrates statistical analysis and knowledge question and answer functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a272a7",
   "metadata": {},
   "source": [
    "## 1. Review of the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97210515",
   "metadata": {},
   "source": [
    "In order to better understand the contents of this chapter, we first briefly review the key contents of the first two chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9b07c",
   "metadata": {},
   "source": [
    "Chapter 14 introduces the construction process of the paper question and answer system, explains the core components in turn, such as parser, retriever, reranker, etc., and shows how to gradually build a complete RAG system. At the same time, we also discussed some advanced techniques to improve the performance and flexibility of the system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74786d61",
   "metadata": {},
   "source": [
    "![image.png](16_images/img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de1ef7",
   "metadata": {},
   "source": [
    "However, this system still belongs to the traditional RAG architecture. In Chapter 15, we further pointed out the limitations of traditional RAG in dealing with statistical problems and proposed solutions, such as combining SQL database, Text2SQL technology and sql\\_tool tool. However, the previous chapter only proposed a theoretical scheme and has not yet given a complete practical example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932cae4f",
   "metadata": {},
   "source": [
    "Therefore, this chapter will build on this basis and combine it with actual cases to build a more complete and practical statistical question and answer system to further expand RAG's capabilities in structured data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e079a0",
   "metadata": {},
   "source": [
    "## 2. Overview of this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657369d2",
   "metadata": {},
   "source": [
    "In this chapter, we will further expand its functions based on the existing paper question and answer system, so that the system can not only perform knowledge question and answer, but also have the ability to handle statistical analysis tasks. To this end, we need to adjust the traditional RAG architecture to enhance its adaptability in statistical scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95d585",
   "metadata": {},
   "source": [
    "Since there are significant differences in the processing logic and the types of information they rely on between knowledge question and answer and statistical question and answer, it is difficult in practice to use a unified pipeline to meet both needs. Therefore, we added a new pipeline specifically for processing statistical tasks based on the original RAG pipeline to realize the change in system structure from [Figure 1] to [Figure 2]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28aabbd3",
   "metadata": {},
   "source": [
    "![image.png](16_images/img2.png)\n",
    "\n",
    "Figure 1 System architecture diagram of the original paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ee495f1",
   "metadata": {},
   "source": [
    "![image.png](16_images/img3.png)\n",
    "\n",
    "Figure 2 Architecture diagram of a question and answer system with statistical capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49106b",
   "metadata": {},
   "source": [
    "On the basis of reusing existing modules, we have added a new statistical analysis pipeline for database query, statistical analysis and chart generation. This pipeline runs in parallel with the RAG pipeline and is uniformly scheduled through an intent recognition module. This module is responsible for determining whether the user query belongs to knowledge question and answer or statistical analysis, thereby guiding the request into the appropriate processing flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a05ba7",
   "metadata": {},
   "source": [
    "In order to realize this enhanced system, we also need to introduce several key technical modules. Next, these new modules and their functions in the system will be introduced one by one after completing the data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9024f",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb2fe4",
   "metadata": {},
   "source": [
    "Here we take the [ArXivQA](https://github.com/taesiri/ArXivQA) data set as an example, and extract the first 100 papers from Papers-2024.md for demonstration. Before executing the code, you need to download Papers-2024.md, which can be downloaded offline or with the following command. This file contains paper information and download links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43796cdf",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "wget https://raw.githubusercontent.com/taesiri/ArXivQA/main/Papers-2024.md -O 2024.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77378aa3",
   "metadata": {},
   "source": [
    "We need to prepare data from two aspects:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c853b5d",
   "metadata": {},
   "source": [
    "1. **Knowledge Base** (download the paper file to the specified directory), used for knowledge Q&A;\n",
    "\n",
    "2. **Database** (the table that constructs the paper information is stored in the local database), used for statistical question and answer, paper information such as title, author, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671878a",
   "metadata": {},
   "source": [
    "The following script can simultaneously download a paper to a specified folder and build a database of paper information.\n",
    "\n",
    "[GitHub link ðŸ”—](https://github.com/LazyAGI/Tutorial/blob/7abc91dbb82a007a78731845dd8c360ac0cc1e75/rag/codes/chapter16/CreateDataBase.py#L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Function to download files\n",
    "def spider(url, save_dir='./rag_data/papers'):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request is successful\n",
    "    res = {}\n",
    "    if response.status_code == 200:\n",
    "        # Parse web page content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        elements = soup.find_all(class_='title mathjax')\n",
    "        for ele in elements:\n",
    "            res['title'] = ele.get_text().replace(\"Title:\", '')\n",
    "        elements = soup.find_all(class_='authors')\n",
    "        authors = []\n",
    "        for ele in elements:\n",
    "            links = ele.find_all('a')\n",
    "            for link in links:\n",
    "                authors.append(link.get_text())\n",
    "        res['author'] = ';'.join(authors)\n",
    "        elements = soup.find_all(class_='tablecell subjects')\n",
    "        for ele in elements:\n",
    "            res['subject'] = ele.get_text()\n",
    "           \n",
    "        # Save paper\n",
    "        file_path = os.path.join(save_dir, res['title'] + '.pdf')\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved PDF to {file_path}\")\n",
    "        return res\n",
    "\n",
    "    else:\n",
    "        print(f\"Webpage loading failed, status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def get_information():\n",
    "    with open('2024.md')as f:\n",
    "        texts = f.readlines()[2:102]\n",
    "\n",
    "    reses = []\n",
    "    for text in tqdm(texts):\n",
    "        abs_url = re.findall(r'\\[.*?\\]\\((https?://arxiv.*?)\\)', text)\n",
    "        if len(abs_url) > 0:\n",
    "            res = spider(abs_url[0])\n",
    "            reses.append(res)\n",
    "            time.sleep(5)\n",
    "\n",
    "    with open('test.txt', 'w')as f:\n",
    "        json.dump({\"data\": reses}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccd32c",
   "metadata": {},
   "source": [
    "The above is a script to obtain document information, which is responsible for parsing the data in 2024.md, taking 100 articles as an example, and then parsing the corresponding URLs, and then obtaining the information of the paper title, author, and topic corresponding to each URL, and recording it.\n",
    "\n",
    "[Code Blocks GitHub link ðŸ”—](https://github.com/LazyAGI/Tutorial/blob/7abc91dbb82a007a78731845dd8c360ac0cc1e75/rag/codes/chapter16/CreateDataBase.py#L52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ecb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "\n",
    "def write_into_table():\n",
    "    with open('test.txt', 'r')as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data = data['data']\n",
    "\n",
    "    # Connect to the SQLite database (if the database does not exist, it will be created)\n",
    "    conn = sqlite3.connect('papers.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    #Create table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS papers (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        title TEXT,\n",
    "        author TEXT,\n",
    "        subject TEXT\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    #Insert data\n",
    "    for paper in data:\n",
    "        cursor.execute('''\n",
    "        INSERT INTO papers (title, author, subject)\n",
    "        VALUES (?, ?, ?)\n",
    "        ''', (paper['title'], paper['author'], paper['subject']))\n",
    "\n",
    "    # Submit and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e00f6a",
   "metadata": {},
   "source": [
    "The above code creates the corresponding database information based on the obtained information, and writes the record information for SQL Call query. Now that we have completed the data preparation, we have obtained the downloaded paper in the fixed directory:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68d36e06",
   "metadata": {},
   "source": [
    "![image.png](16_images/img4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cedbfd",
   "metadata": {},
   "source": [
    "and the database file `papers.db`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d22a9a86",
   "metadata": {},
   "source": [
    "![image.png](16_images/img5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f08559",
   "metadata": {},
   "source": [
    "## 4. Detailed explanation of dependent modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f4c012",
   "metadata": {},
   "source": [
    "In order to build a question and answer system that supports statistical analysis, we need to master the principles and implementation methods of several core modules, including intent recognition, SQL calling, statistical analysis, and chart generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5265e4",
   "metadata": {},
   "source": [
    "### 1. Intent recognition\n",
    "   \n",
    "The first is the intent recognition module. The main responsibility of this module is to analyze the user's input content and determine whether the intention is traditional knowledge Q&A or statistical Q&A involving structured data processing.\n",
    "   \n",
    "LazyLLM has a built-in IntentClassifier class for analyzing intentions. The details are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0be928",
   "metadata": {},
   "source": [
    "IntentClassifier is a language model-based intent recognizer that identifies predefined intents based on user-provided input text and conversation context, and ensures accurate recognition of intents through pre- and post-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173084c",
   "metadata": {},
   "source": [
    "For IntentClassifier we provide the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c9618",
   "metadata": {},
   "source": [
    "* llm: Language model object used for intent recognition, OnlineChatModule or TrainableModule type\n",
    "* intent\\_list (list): A list of strings containing all possible intentions. Can contain Chinese or English intent.\n",
    "* prompt (str): prompt word appended by the user.\n",
    "* constrain (str): User-attached constraints.\n",
    "* examples (list[list]): Additional examples in the format `[[query, intent], [query, intent], ...]` .\n",
    "* return\\_trace (bool, optional): If set to True, the results will be recorded in trace. Default is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d56f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_prompt_classifier_template = \"\"\"\n",
    "## role: intent classifier\n",
    "You are an intent classification engine responsible for analyzing user input text and determining unique intent categories based on conversational information. {user_prompt}\n",
    "\n",
    "## limit:\n",
    "You only need to reply the name of the intent, no additional fields are output, and no translation is required. {user_constrains}\n",
    "\n",
    "## Notice:\n",
    "{attention}\n",
    "\n",
    "## Text format\n",
    "The input text is in JSON format, the content in \"human_input\" is the user's original input, and \"intent_list\" is a list of all intent names.\n",
    "\n",
    "## Example\n",
    "User: {{\"human_input\": \"How will the weather be in Beijing tomorrow?\", \"intent_list\": [\"View weather\", \"Search engine search\", \"View monitoring\", \"Weekly report summary\", \"Chat\"]}}\n",
    "Assistant: Check the weather\n",
    "{user_examples}\n",
    "\n",
    "## Historical Dialogue\n",
    "The chat history between the human and the assistant is stored in the <histories></histories> XML tag below.\n",
    "<histories>\n",
    "{history_info}\n",
    "</histories>\n",
    "\n",
    "Enter the text as follows:\n",
    "\"\"\"  # noqa E501\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87647e9e",
   "metadata": {},
   "source": [
    "Within IntentClassifier, the template shown above is built-in, which is used to pass the above parameters into the large model. The call to IntentClassifier is very simple. Here are two complete call examples [Code Github linkðŸ”—](https://github.com/LazyAGI/Tutorial/blob/7abc91dbb82a007a78731845dd8c360ac0cc1e75/rag/codes/chapter16/intent_classifier.py#L1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazyllm\n",
    "from lazyllm.tools import IntentClassifier\n",
    "\n",
    "classifier_llm = lazyllm.OnlineChatModule()\n",
    "chatflow_intent_list = [\"Translation Service\", \"Weather Inquiry\", \"Content Recommendation\", \"Financial Quotation Inquiry\"]\n",
    "classifier = IntentClassifier(classifier_llm, intent_list=chatflow_intent_list)\n",
    "\n",
    "while True:\n",
    "    query = input(\"Enter your question:\\n\")\n",
    "    print(f\"\\nThe recognized intent is:\\n {classifier(query)}\\n\" + \"-\"*40)\n",
    "\n",
    "#Whatâ€™s the weather like today âž” Weather query\n",
    "# How is the A-share market? âž” Financial market inquiry\n",
    "# Recommend a science fiction movie to me âž” Content recommendation\n",
    "# Help me translate this paper into Chinese âž” Translation Service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f188d",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin:20px 0;\">\n",
    "  <video controls style=\"width:900px; max-width:100%; height:auto; border:1px solid #ccc; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.1);\">\n",
    "    <source src=\"./16_videos/intent.mp4\" type=\"video/mp4\" />\n",
    "    Your browser does not support the video tag.\n",
    "  </video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d92ade",
   "metadata": {},
   "source": [
    "#### Intent recognition-advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67499273",
   "metadata": {},
   "source": [
    "Through the with syntax, the intent recognition module can directly follow specific instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a09cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = TrainableModule('internlm2-chat-7b')\n",
    "with IntentClassifier(base) as ic:\n",
    "    ic.case['Chat', base]\n",
    "    ic.case['Voice Recognition', TrainableModule('SenseVoiceSmall')]\n",
    "    ic.case['Picture Q&A', TrainableModule('Mini-InternVL-Chat-2B-V1-5').deploy_method(deploy.LMDeploy)]\n",
    "    ic.case['Paint', pipeline(base.share().prompt(painter_prompt),\n",
    "        TrainableModule('stable-diffusion-3-medium'))]\n",
    "    ic.case['Generate music', pipeline(base.share().prompt(musician_prompt), TrainableModule('musicgen-small'))]\n",
    "    ic.case['Text to speech', TrainableModule('ChatTTS')]\n",
    "    WebModule(ic, history=[base], audio=True, port=8847).start().wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a9567",
   "metadata": {},
   "source": [
    "â€¢ There are three usage methods: case[a, b], case[a: b] and case[a::b]. You can choose to use any of the three according to your personal habits. There is no difference between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with IntentClassifier(base) as ic:\n",
    "    ic.case['Chat', base]\n",
    "    ic.case['Voice Recognition': TrainableModule('SenseVoiceSmall')]\n",
    "    ic.case['Picture Q&A'::TrainableModule('Mini-InternVL-Chat-2B-V1-5').deploy_method(deploy.LMDeploy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8ac8a",
   "metadata": {},
   "source": [
    "### 2. Sql Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c4313",
   "metadata": {},
   "source": [
    "Next, we solve the first link in the statistical Q&A process: database query and data acquisition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dca6f",
   "metadata": {},
   "source": [
    "In the previous learning content, although we used SQLite as an example to explain the basic usage process of the database, in a real production environment, the types of databases used are far more than SQLite. Common relational databases also include MySQL, PostgreSQL, SQL Server, Oracle, etc. In the cloud, database services such as Alibaba Cloud RDS, Tencent Cloud CynosDB, and AWS RDS are also widely used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff63d7",
   "metadata": {},
   "source": [
    "In order to easily connect and operate different types of databases, we can use the very popular ORM framework in Python - â€‹**SQLAlchemy**â€‹. SQLAlchemy provides a unified database operation interface, supporting not only local databases, but also various mainstream cloud databases, which greatly improves the flexibility and scalability of database interaction. The following is the code to connect local and remote databases through **SQLAlchemy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Create a SQLite local database connection\n",
    "engine = create_engine('sqlite:///local_database.db')\n",
    "#Create a remote MySQL database connection\n",
    "# Format: mysql+pymysql://username:password@server address:port/database name\n",
    "engine = create_engine('mysql+pymysql://user:password@host:3306/database_name')\n",
    "\n",
    "# Test connection\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(\"SELECT 1\")\n",
    "    print(result.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b7c58",
   "metadata": {},
   "source": [
    "In the lazyllm framework, this function is also encapsulated and the built-in **SQLManager** module is provided. Through SQLManager, users can easily connect to local or cloud databases, call SQL queries uniformly, and perform SQL-call related operations without having to worry about the complex details of the underlying connection. Just specify the database address, account password and other information in the configuration, and you can start the database interaction capability with one click, laying a solid foundation for subsequent structured Q&A.\n",
    "[Code Blocks GitHub link ðŸ”—](https://github.com/LazyAGI/Tutorial/blob/7abc91dbb82a007a78731845dd8c360ac0cc1e75/rag/codes/chapter16/sql_manager.py#L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazyllm.tools import SqlManager\n",
    "\n",
    "# Connect to local database\n",
    "sql_manager = SqlManager(\"sqlite\", None, None, None, None, db_name=\"papers.db\",   tables_info_dict=table_info)\n",
    "# Connect to remote database\n",
    "# sql_manager = SqlManager(type=\"PostgreSQL\", user=\"\", password=\"\", host=\"\",port=\"\", name=\"\",)\n",
    "\n",
    "# Query the number of all papers\n",
    "res = sql_manager.execute_query(\"select count(*) as total_papser from papers;\")\n",
    ">>> [{\"total_papser\": 100}]\n",
    "\n",
    "# Query the titles of papers with LLM\n",
    "res = sql_manager.execute_query(\"select title from papers where title like '%LLM%'\")\n",
    ">>> [{\"title\": \"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\"}, {\"title\": \"Learning to Localize Objects Improves Spatial Reasoning in Visual-LLMs\"}, {\"title\": \"LLMs in Biomedicine: A study on clinical Named Entity Recognition\"}, {\"title\": \"VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c85368",
   "metadata": {},
   "source": [
    "Note that the `db_name` parameter needs to be passed in the path to the constructed database file, and the `tables_info_dict` parameter needs to be passed in the database basic information dictionary (table name, column name, etc.). We take the paper database as an example. The basic information is defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = {\n",
    "    \"tables\": [{\n",
    "        \"name\": \"papers\",\n",
    "        \"comment\": \"paper data\",\n",
    "        \"columns\": [\n",
    "            {\n",
    "                \"name\": \"id\",\n",
    "                \"data_type\": \"Integer\",\n",
    "                \"comment\": \"serial number\",\n",
    "                \"is_primary_key\": True,\n",
    "            },\n",
    "            {\"name\": \"title\", \"data_type\": \"String\", \"comment\": \"title\"},\n",
    "            {\"name\": \"author\", \"data_type\": \"String\", \"comment\": \"author\"},\n",
    "            {\"name\": \"subject\", \"data_type\": \"String\", \"comment\": \"field\"},\n",
    "        ],\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea42ee2",
   "metadata": {},
   "source": [
    "### 3. Sql Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101a5df",
   "metadata": {},
   "source": [
    "The SQL Call module relies on Sql Manager, which can generate SQL query statements that meet semantic intent based on user questions and connect to the back-end database to obtain original data. This module is not only the entrance to statistical analysis, but also the key to ensuring the accuracy of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff7d2b",
   "metadata": {},
   "source": [
    "Letâ€™s first take a look at the contents of the database file `papers.db` that we have constructed during the data preparation stage. There is only one table in the database, containing the title, author and subject information of the article:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3519609",
   "metadata": {},
   "source": [
    "![image.png](16_images/img6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7be1f",
   "metadata": {},
   "source": [
    "Next start defining sql call:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6cdce",
   "metadata": {},
   "source": [
    "* Create sql\\_manager by specifying the database name and data table information, and instantiate a large model to implement text2sql.\n",
    "* Pass both in to build a SQL Call workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de312ef",
   "metadata": {},
   "source": [
    "This workflow supports converting natural language queries into SQL statements and executing the queries, ultimately returning results.\n",
    "[Code GitHub linkðŸ”—](https://github.com/LazyAGI/Tutorial/blob/7abc91dbb82a007a78731845dd8c360ac0cc1e75/rag/codes/chapter16/sql_call.py#L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dce4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazyllm.tools import SqlManager, SqlCall\n",
    "\n",
    "sql_manager = SqlManager(\"sqlite\", None, None, None, None, db_name=\"papers.db\",   tables_info_dict=table_info)\n",
    "sql_llm = lazyllm.OnlineChatModule()\n",
    "sql_call = SqlCall(sql_llm, sql_manager, \n",
    "  use_llm_for_sql_result=False)\n",
    "\n",
    "query = \"How many articles are there in the library?\"\n",
    "print(sql_call(query))\n",
    ">>> [{\"total_papers\": 200}]\n",
    "while True:\n",
    "  query = input(\"Please enter your question:\")\n",
    "    print(\"answerï¼š\")\n",
    "    print(sql_call(query))\n",
    "# How many papers are there in the library?\n",
    "#What are the three most subjects in the library?\n",
    "# Query the database and return the results of thesis topics whose subject contains Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01332256",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin:20px 0;\">\n",
    "  <video controls style=\"width:900px; max-width:100%; height:auto; border:1px solid #ccc; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.1);\">\n",
    "    <source src=\"./16_videos/sql_call.mp4\" type=\"video/mp4\" />\n",
    "    Your browser does not support the video tag.\n",
    "  </video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea667a6",
   "metadata": {},
   "source": [
    "### 4. Statistical analysis agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d874c8",
   "metadata": {},
   "source": [
    "After the problem of obtaining data is solved, we will enter the core process of statistical analysis. This module implements the entire statistical analysis pipeline based on sql call. It can be regarded as an intelligent agent oriented to statistical tasks. It can automatically complete the complete closed-loop process of **database query â†’ data analysis â†’ chart generation â†’ result summary** according to user questions. Provide users with answers with pictures and text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69755ebb",
   "metadata": {},
   "source": [
    "![image.png](16_images/img7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786e58b",
   "metadata": {},
   "source": [
    "#### (1) Code writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773d622",
   "metadata": {},
   "source": [
    "We first define two tools (Tools) for **SQL query** and â€‹**code execution**â€‹, and provide them to the Agent as optional tools to support it in completing database queries and statistical analysis during task execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dfef2",
   "metadata": {},
   "source": [
    "* The `run_sql_query` method is encapsulated based on the SQL Call workflow built in the previous section. The Agent can call this method after parsing the SQL-related requirements from the user query to obtain structured query results.\n",
    "* The `run_code` method is used to receive and execute the statistical analysis code generated by the large model. This method will return key results or error information to provide feedback basis for the next decision and action of the large model.\n",
    "  \n",
    "These two tools work together to enable Agent to dynamically complete the entire process from data acquisition to analysis and execution.\n",
    "\n",
    "[Code GitHub linkðŸ”—](https://github.com/LazyAGI/Tutorial/blob/main/rag/codes/chapter16/utils/bi_tools.py#L64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e54f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "@fc_register(\"tool\")\n",
    "def run_sql_query(query):\n",
    "    \"\"\"\n",
    "    Automatically generates and executes an SQL query based on a natural language request.\n",
    "\n",
    "    Given a natural language query describing a data retrieval task, this function generates the corresponding SQL \n",
    "    statement, executes it against the database, and returns the result.\n",
    "\n",
    "    Args:\n",
    "        query (str): A natural language description of the desired database query.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of records returned from the SQL query, where each record is represented as a dictionary.\n",
    "    \"\"\"\n",
    "    sql_manager = SqlManager(\"sqlite\", None, None, None, None, db_name=\"papers.db\", tables_info_dict=table_info)\n",
    "    sql_llm = lazyllm.OnlineChatModule(source=\"sensenova\")\n",
    "    sql_call = SqlCall(sql_llm, sql_manager, use_llm_for_sql_result=False)\n",
    "    return sql_call(query)\n",
    "\n",
    "\n",
    "@fc_register(\"tool\")\n",
    "def run_code(code: str):\n",
    "    \"\"\"\n",
    "    Run the given code in a separate thread and return the result.\n",
    "\n",
    "    Args:\n",
    "        code (str): code to run.\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"text\": str,\n",
    "            \"error\": str or None,\n",
    "        }\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"text\": \"\",\n",
    "        \"error\": None,\n",
    "    }\n",
    "\n",
    "    def code_thread():\n",
    "        nonlocal result\n",
    "        stdout = io.StringIO()\n",
    "        try:\n",
    "            with contextlib.redirect_stdout(stdout):\n",
    "                exec_globals = {}\n",
    "                exec(code, exec_globals)\n",
    "        except Exception:\n",
    "            result[\"error\"] = traceback.format_exc()\n",
    "        result[\"text\"] = stdout.getvalue()\n",
    "\n",
    "    thread = threading.Thread(target=code_thread)\n",
    "    thread.start()\n",
    "    thread.join(timeout=10)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        result[\"error\"] = \"Execution timed out.\"\n",
    "        thread.join()  \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e739213",
   "metadata": {},
   "source": [
    ">Attention! When writing a function, be sure to add a comment below the function in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunction(arg1: str, arg2: Dict[str, Any], arg3: Literal[\"aaa\", \"bbb\", \"ccc\"]=\"aaa\"):\n",
    "       '''\n",
    "       Function description ...\n",
    "\n",
    "       Args:\n",
    "              arg1 (str): arg1 description.\n",
    "              arg2 (Dict[str, Any]): arg2 description\n",
    "              arg3 (Literal[\"aaa\", \"bbb\", \"ccc\"]): arg3 description\n",
    "       '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16444ba0",
   "metadata": {},
   "source": [
    "> When the large model calls this function, the description of the function and the expression of the parameters will be used to determine when to call and pass in the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4003c",
   "metadata": {},
   "source": [
    "Next we implement the agent definition. Here we use lazyllm's built-in ReactAgent tool and pass the two tools defined previously into the tools parameter to realize automatic invocation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a0870",
   "metadata": {},
   "source": [
    "> ReactAgent follows the process of `Thought->Action->Observation->Thought...->Finish` to display the steps to solve user problems step by step through LLM and tool calls, and finally outputs the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazyllm.tools.agent import ReactAgent\n",
    "\n",
    "agent = ReactAgent(\n",
    "        llm=lazyllm.OnlineChatModule(stream=False),\n",
    "        tools=['run_code', 'run_sql_query'],\n",
    "        return_trace=True,\n",
    "        max_retries=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49722849",
   "metadata": {},
   "source": [
    "Then based on the above agent, we define prompt and build a SQL question and answer process that supports statistical questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9543449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_prompt = \"\"\"\n",
    "You are a senior data scientist who needs to perform the necessary statistical analysis and drawing based on given questions to answer statistical questions raised by users.\n",
    "Your workflow would look like this:\n",
    "\n",
    "1. Understand the problem and conduct data query\n",
    "- Disassemble the part of the problem that needs to be queried in the database, and call the corresponding tools to obtain data.\n",
    "\n",
    "2. Determine whether answers to statistical questions can be obtained directly from the data\n",
    "- If the data can directly answer the statistical question, output the results directly and draw charts if necessary.\n",
    "- If it is not enough to answer, perform necessary data analysis first and then draw graphs if necessary.\n",
    "\n",
    "3. Implement data analysis and graphing by writing code, executing it, and obtaining results.\n",
    "- Write complete executable Python code, including all necessary imports, data loading, analysis logic, drawing code, and result output.\n",
    "- Perform data analysis using common data science toolkits such as pandas, numpy, scikit-learn, etc.\n",
    "- Use visualization tools (such as matplotlib, seaborn) for charting.\n",
    "\n",
    "4. Image saving\n",
    "- All generated images must be saved to the following path:\n",
    "     {image_path}\n",
    "- After successful saving, use the following format to display the image in the final answer (Answer part) (image_name is the saved file name, image_path is the full path):\n",
    "     ![image_name](image_path)\n",
    "\n",
    "5. Error handling\n",
    "- If the code execution fails, please automatically modify the code according to the error message and re-execute it until it succeeds.\n",
    "\n",
    "question:\n",
    "{query}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with pipeline() as sql_ppl:\n",
    "    sql_ppl.formarter = lambda query: sql_prompt.format(query=query, image_path=IMAGE_PATH) \n",
    "    sql_ppl.agent = ReactAgent(\n",
    "            llm=lazyllm.OnlineChatModule(stream=False),\n",
    "            tools=['run_code', 'run_sql_query'],\n",
    "            return_trace=True,\n",
    "            max_retries=3,\n",
    "        )\n",
    "    sql_ppl.clean_output = lazyllm.ifs(lambda x: \"Answer:\" in x, lambda x: x.split(\"Answer:\")[-1], lambda x:x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lazyllm.WebModule(sql_ppl, port=23456, static_paths=image_save_path).start().wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e396856",
   "metadata": {},
   "source": [
    "#### (2) Result display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9776ed4",
   "metadata": {},
   "source": [
    "Let us sort out the complete execution process of the code based on a simple example query:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193dde7",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin:20px 0;\">\n",
    "  <video controls style=\"width:900px; max-width:100%; height:auto; border:1px solid #ccc; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.1);\">\n",
    "    <source src=\"./16_videos/function_call.mp4\" type=\"video/mp4\" />\n",
    "    Your browser does not support the video tag.\n",
    "  </video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9e513",
   "metadata": {},
   "source": [
    "## 5. Construct a paper question and answer system that supports statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970c851",
   "metadata": {},
   "source": [
    "After mastering the key technologies on which the system relies, we can begin to build a practical system to support the integration of statistical analysis and knowledge question and answer capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713413db",
   "metadata": {},
   "source": [
    "The architecture of the entire system is as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea21e9ac",
   "metadata": {},
   "source": [
    "![image.png](16_images/img8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488cfee",
   "metadata": {},
   "source": [
    "[Code implementation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3407a",
   "metadata": {},
   "source": [
    "Letâ€™s take a look at how to use the structure given above to build a complete multi-functional Q&A workflow. The overall idea is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35eb7a2",
   "metadata": {},
   "source": [
    "We first define two sub-workflows respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c6b58",
   "metadata": {},
   "source": [
    "* `chat_ppl`: used to handle general question and answer tasks based on RAG (Retrieval-Augmented Generation);\n",
    "* `sql_ppl`: used to handle SQL question and answer tasks related to statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e162c",
   "metadata": {},
   "source": [
    "Subsequently, an **intent recognition module**â€‹ was introduced into the main workflow to parse the user's query intention, and accordingly select the appropriate path for processing in the two sub-workflows of `chat_ppl` and `sql_ppl`. Through such a structural design, the system can automatically match appropriate workflows according to the type of user questions, and achieve unified scheduling and processing of natural language question answering and statistical analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57988d3a",
   "metadata": {},
   "source": [
    "** Note that in lines 9 and 10, we import the rag pipeline introduced in Chapter 14 ([`build_paper_rag()`](https://github.com/LazyAGI/Tutorial/blob/main/rag/codes/chapter16/paper_rag.py#L43)â€‹) and the sql defined above through module import. pipeline ([`build_statistical_agent()`](https://github.com/LazyAGI/Tutorial/blob/main/rag/codes/chapter16/statistical_agent.py#L8)), no repeated coding here. **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0c416",
   "metadata": {},
   "source": [
    "[Code GitHub linkðŸ”—](https://github.com/LazyAGI/Tutorial/blob/main/rag/codes/chapter16/paper_assistant.py#L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazyllm\n",
    "from lazyllm import OnlineChatModule, pipeline, _0\n",
    "from lazyllm.tools import IntentClassifier\n",
    "\n",
    "from statistical_agent import build_statistical_agent\n",
    "from paper_rag import build_paper_rag\n",
    "\n",
    "# Build rag workflow and statistical analysis workflow\n",
    "rag_ppl = build_paper_rag()\n",
    "sql_ppl = build_statistical_agent()\n",
    "\n",
    "# Build a main workflow with knowledge Q&A and statistical Q&A capabilities\n",
    "def build_paper_assistant():\n",
    "    llm = OnlineChatModule(source='qwen', stream=False)\n",
    "    intent_list = [\n",
    "        \"Essay Questions and Answers\",\n",
    "        \"Statistics Q&A\",\n",
    "    ]\n",
    "\n",
    "    with pipeline() as ppl:\n",
    "        ppl.classifier = IntentClassifier(llm, intent_list=intent_list)\n",
    "        with lazyllm.switch(judge_on_full_input=False).bind(_0, ppl.input) as ppl.sw:\n",
    "            ppl.sw.case[intent_list[0], rag_ppl]\n",
    "            ppl.sw.case[intent_list[1], sql_ppl]\n",
    "\n",
    "    return ppl\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_ppl = build_paper_assistant()\n",
    "    lazyllm.WebModule(main_ppl, port=23459, static_paths=\"./images\").start().wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3970706",
   "metadata": {},
   "source": [
    "Then we can start the workflow. We use WebModule to start the service, and create the workflow defined above into a web service through WebModule. It should be noted here that when starting WebModule, you need to pass in the saving path of the image, so that the directory can be set as a static directory, and Gradio can directly access the image files in this directory. When the web service is started successfully, we can experience using it in the browser based on the IP and port after startup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ba3be",
   "metadata": {},
   "source": [
    "[Effect display]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290221b",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin:20px 0;\">\n",
    "  <video controls style=\"width:900px; max-width:100%; height:auto; border:1px solid #ccc; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.1);\">\n",
    "    <source src=\"./16_videos/sql+fuc.mp4\" type=\"video/mp4\" />\n",
    "    Your browser does not support the video tag.\n",
    "  </video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c18b71",
   "metadata": {},
   "source": [
    "### **Simple statistical questions (no drawing required)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd5228e0",
   "metadata": {},
   "source": [
    "![image.png](16_images/img9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d818677",
   "metadata": {},
   "source": [
    "**Processing process analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb321a",
   "metadata": {},
   "source": [
    "1. The user enters query **\"How many papers are there in the library\"**\n",
    "\n",
    "2. Large model extraction data query question \"How many papers are there in the library?\" Call `SqlCall`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ce683",
   "metadata": {},
   "source": [
    "```bash\n",
    "inputï¼š \n",
    "\"How many papers are there in the library?\"\n",
    "\n",
    "text2sqlï¼š\n",
    "select count(*) as total_papser from papers;\n",
    "\n",
    "outputï¼š\n",
    "[{\"total_papers\": 100}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2d1fe",
   "metadata": {},
   "source": [
    "3. The model determines that the result can answer the query question, and directly outputs the answer \"There are a total of 100 papers in the library.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfc6d1",
   "metadata": {},
   "source": [
    "[Attachment: Execution log]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7e0032e",
   "metadata": {},
   "source": [
    "![image.png](16_images/img10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebca20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e7eff",
   "metadata": {},
   "source": [
    "### Simple statistical questions (requires drawing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc5dd5c9",
   "metadata": {},
   "source": [
    "![image.png](16_images/img11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25b8a1",
   "metadata": {},
   "source": [
    "1. The user enters query **\"Based on the data in the database, tell me what the three most subjects are and draw a histogram\"**\n",
    "\n",
    "2. The large model will analyze the incoming `query` and determine that the run\\_sql\\_query tool needs to be called to obtain data. It will call the built-in Sql scheduling tool `SqlCall` of `lazyllm`, which can automatically execute the corresponding sql query statement and obtain the corresponding results from the database. The results are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf7254",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "```bash\n",
    "inputï¼š\n",
    "\"Find the three most numerous subjects in the database and their quantities\"\n",
    " \n",
    "text2sqlï¼š\n",
    "select subject, count(*) as count\n",
    "from papsers\n",
    "group by count desc\n",
    "limit 3;\n",
    "\n",
    "outputï¼š\n",
    "[{\"subject\": \"\\nComputer Vision and Pattern Recognition (cs.CV)\", \"count\": 25}, {\"subject\": \"\\nRobotics (cs.RO)\", \"count\": 6}, {\"subject\": \"\\nComputation and Language (cs.CL)\", \"count\": 5}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117a959",
   "metadata": {},
   "source": [
    "3. The model determines that the result can already answer the question of query, and no further statistical analysis is required. However, the query contains drawing requirements, so it writes python code only for drawing and calls the run\\_code tool for execution. The following is the code written for the large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24acdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# data\n",
    "labels = ['Computer Vision and Pattern Recognition (cs.CV)', 'Robotics (cs.RO)', 'Computation and Language (cs.CL)']\n",
    "counts = [25, 6, 5]\n",
    "\n",
    "#Create a histogram\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "rects = ax.bar(x, counts, width)\n",
    "\n",
    "# Add labels, titles and ticks\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Top Three Subjects')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "# show chart\n",
    "plt.tight_layout()\n",
    "image_path = './images/top_three_subjects.png'\n",
    "plt.savefig(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e823d35",
   "metadata": {},
   "source": [
    "4. After the drawing is completed, the large model will generate a final answer with pictures and text for the user based on the picture path and integrating the previous results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a0c35",
   "metadata": {},
   "source": [
    "[Attachment: Execution log]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bf727d8",
   "metadata": {},
   "source": [
    "![image.png](16_images/img12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963209b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db8557",
   "metadata": {},
   "source": [
    "### Complex statistical problems (requires drawing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba8375be",
   "metadata": {},
   "source": [
    "![image.png](16_images/img13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ece4e0",
   "metadata": {},
   "source": [
    "**Processing process analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2930eb",
   "metadata": {},
   "source": [
    "1. The user inputs query **\"Query the titles of all papers in the database, cluster the papers into 5 categories based on the title content, list several articles in each category, and use a bar chart to display the number of papers in each category\"**\n",
    "\n",
    "2. Large model extraction data query question \"How many papers are there in the library?\" Call `SqlCall`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1162798",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "```bash\n",
    "inputï¼š \n",
    "\"Query all paper titles in the database\"\n",
    "\n",
    "text2sqlï¼š\n",
    "select title from papers;\n",
    "\n",
    "outputï¼š\n",
    "[\"View Selection for 3D Captioning via Diffusion Ranking\", \"The Role of Language Imbalance in Cross-lingual Generalisation: Insights from Cloned Language Experiments\", \"OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments\", \"Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models\", \"Rho-1: Not All Tokens Are What You Need\", \"Lyapunov-stable Neural Control for State and Output Feedback: A Novel Formulation\", \"On Unified Prompt Tuning for Request Quality Assurance in Public Code Review\", \"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\", \"High-Dimension Human Value Representation in Large Language Models\", \"Overparameterized Multiple Linear Regression as Hyper-Curve Fitting\", ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2a172",
   "metadata": {},
   "source": [
    "3. The model writing program further performs statistical analysis tasks and calls the `run code` tool for execution.\n",
    "\n",
    "[Full code GitHub linkðŸ”—](https://github.com/LazyAGI/Tutorial/blob/7abc91dbb82a007a78731845dd8c360ac0cc1e75/rag/codes/chapter16/chat_sql_qa.py#L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data = [\"View Selection for 3D Captioning via Diffusion Ranking\", \"The Role of Language Imbalance in Cross-lingual Generalisation: Insights from Cloned Language Experiments\", \"OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments\", \"Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models\", \"Rho-1: Not All Tokens Are What You Need\", \"Lyapunov-stable Neural Control for State and Out...\"]\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=['title'])\n",
    "\n",
    "# Vectorize titles\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X = tfidf.fit_transform(df['title'])\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Count papers per cluster\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "\n",
    "# Plot cluster counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "cluster_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of Papers per Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Save plot\n",
    "os.makedirs('./images', exist_ok=True)\n",
    "image_path = './images/cluster_counts.png'\n",
    "plt.savefig(image_path)\n",
    "plt.close()\n",
    "\n",
    "# Print cluster counts and example titles\n",
    "print(\"Cluster Counts:\")\n",
    "print(cluster_counts)\n",
    "print(\"\\nExample Titles per Cluster:\")\n",
    "for cluster in range(5):\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    print(df[df['cluster'] == cluster]['title'].head(3).to_string(index=False))\n",
    "\n",
    "print(f\"\\nImage saved at: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adff60f",
   "metadata": {},
   "source": [
    "4. After execution, the large model receives the image path and the results of each category, and generates answers with pictures and texts for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaac16f",
   "metadata": {},
   "source": [
    "[Attachment: Operation log]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fd7a481",
   "metadata": {},
   "source": [
    "![image.png](16_images/img15.png)\n",
    "![image-2.png](16_images/img14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf7c80",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e31c1a30",
   "metadata": {},
   "source": [
    "![image.png](16_images/img16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5f3c0",
   "metadata": {},
   "source": [
    "So far, we have built an intelligent question and answer system that has both **knowledge base question answering** and **statistical analysis** capabilities. The system not only supports users to ask semantic questions around the document content, but can also perform statistical analysis and chart drawing on the structured information in the database, thereby supporting global data observation needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc0673",
   "metadata": {},
   "source": [
    "## 6. RAG paper system comprehensive multi-modal solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb2676b8",
   "metadata": {},
   "source": [
    "![image.png](16_images/img17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15deb690",
   "metadata": {},
   "source": [
    "Main code implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build rag workflow and statistical analysis workflow\n",
    "rag_ppl = build_paper_rag()\n",
    "sql_ppl = build_statistical_agent()\n",
    "\n",
    "# Build a main workflow with knowledge Q&A and statistical Q&A capabilities\n",
    "def build_paper_assistant():\n",
    "    llm = OnlineChatModule(source='qwen', stream=False)\n",
    "    vqa = lazyllm.OnlineChatModule(source=\"sensenova\",\\\n",
    "        model=\"SenseNova-V6-Turbo\").prompt(lazyllm.ChatPrompter(gen_prompt))\n",
    "\n",
    "    with pipeline() as ppl:\n",
    "        ppl.ifvqa = lazyllm.ifs(\n",
    "            lambda x: x.startswith('<lazyllm-query>'),\n",
    "            lambda x: vqa(x), lambda x:x)\n",
    "        with IntentClassifier(llm) as ppl.ic:\n",
    "            ppl.ic.case[\"Paper Q&A\", rag_ppl]\n",
    "            ppl.ic.case[\"Statistics Q&A\", sql_ppl]\n",
    "\n",
    "    return ppl\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_ppl = build_paper_assistant()\n",
    "    lazyllm.WebModule(main_ppl, port=23459, static_paths=\"./images\", encode_files=True).start().wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b25381",
   "metadata": {},
   "source": [
    "[Effect display]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c07a7",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin:20px 0;\">\n",
    "  <video controls style=\"width:900px; max-width:100%; height:auto; border:1px solid #ccc; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.1);\">\n",
    "    <source src=\"./16_videos/rag_multimodal.mp4\" type=\"video/mp4\" />\n",
    "    Your browser does not support the video tag.\n",
    "  </video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc61633",
   "metadata": {},
   "source": [
    "## Further reading: Building a database from a knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0695f",
   "metadata": {},
   "source": [
    "Code implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazyllm\n",
    "from lazyllm.tools import SqlManager\n",
    "\n",
    "#Create SQL manager\n",
    "sql_manager = SqlManager(db_type=\"SQLite\", user=None,\n",
    "   password=None, host=None, port=None, db_name=\"doc.db\")\n",
    "#Create knowledge base\n",
    "documents = lazyllm.Document(dataset_path='/path/to/kb', create_ui=False)\n",
    "# Configure extraction fields\n",
    "refined_schema = [\n",
    "    {\"key\": \"document_title\", \"desc\": \"The title of the paper.\", \"type\": \"text\"},\n",
    "    {\"key\": \"author_name\", \"desc\": \"The names of the author of the paper.\", \"type\": \"text\"},\n",
    "    {\"key\": \"keywords\", \"desc\": \"Key terms or themes discussed in the paer.\", \"type\": \"text\"},\n",
    "    {\"key\": \"content_summary\", \"desc\": \"A brief summary of the paper's main content\", \"type\": \"text\"},\n",
    "]\n",
    "# Connect the knowledge base to SQL and set the fields to be extracted\n",
    "documents.connect_sql_manager(\n",
    "    sql_manager=sql_manager,\n",
    "    schma=refined_schema,\n",
    "    force_refresh=True,\n",
    ")\n",
    "# Start extracting the knowledge base into the data set\n",
    "documents.update_database(llm=lazyllm.OnlineChatModule(source=\"qwen\"))\n",
    "# Display the extracted content:\n",
    "str_result = sql_manager.execute_query(f\"select * from {documents._doc_to_db_processor.doc_table_name}\")\n",
    "print(f\"str_result: {str_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421acf8",
   "metadata": {},
   "source": [
    "[Effect display]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28535dcc",
   "metadata": {},
   "source": [
    "![image.png](16_images/img18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        \"lazyllm_uuid\": \"2c42c181-bc26-43ca-a822-505b22f5d19e\",\n",
    "        \"lazyllm_created_at\": \"2025-05-16 19:10:12.014368\",\n",
    "        \"lazyllm_doc_path\": \"/path/to/pdfs/DeepSeek_R1.pdf\",\n",
    "        \"document_title\": \"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\",\n",
    "        \"author_name\": \"DeepSeek-AI\",\n",
    "        \"keywords\": \"DeepSeek-R1-Zero, DeepSeek-R1, reinforcement learning, reasoning models, multi-stage training, open-source, dense models, distilled models, Qwen, Llama\",\n",
    "        \"content_summary\": \"The paper introduces the first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero is trained using large-scale reinforcement learning without supervised fine-tuning and demonstrates strong reasoning capabilities but faces challenges such as poor readability and language mixing. To improve upon this, DeepSeek-R1 incorporates multi-stage training and cold-start data before reinforcement learning, achieving performance comparable to OpenAI-o1-1217 on reasoning tasks. The research community is supported by the open-sourcing of DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Qwen and Llama.\"\n",
    "    }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
